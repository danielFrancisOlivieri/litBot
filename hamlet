# this library produces the sentences using Markov chains
import markovify 

# for language processing 
import nltk, re, pprint
from nltk import word_tokenize

# for html requests
from urllib import request

# playing with twitter
import tweepy

# schedule tweets
import sched, time

# API keys
consumer_key = 'Rcj0tEFxa6BPpSAL3h0ogCUAz'
consumer_secret = 'Sbcao5F4sbx2kmOH8cuwjKXq1YQXjZhJIjI6mH49nrWogvCnGa'
access_token = '911998460425097216-IQlhUlZVlfjOsPGSvUD6LWRiYpzGe6m'
access_token_secret = 'iiWypM5uhFjpleokHo1M2XqppBR4qh4aVRA2BHCat6u8Z'
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)


# inputs the text and cleans it for use 
url = "http://www.gutenberg.org/files/1524/1524-0.txt"
response = request.urlopen(url)
raw = response.read().decode('utf8')
type(raw)

# Build the model.
text_model = markovify.Text(raw)

for i in range(3):
# tweets a randomly-generated sentences of no more than 140 characters
    tweet = text_model.make_short_sentence(280)
    print(tweet)
    api.update_status(tweet)
    time.sleep(30)

